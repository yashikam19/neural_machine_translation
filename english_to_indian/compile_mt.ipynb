{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqTI7HJc3imX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "from collections import Counter\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from torchtext.data.metrics import bleu_score\n",
        "import torch\n",
        "import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "godExJ8w-53v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e04c411c-dfc7-422f-e7e8-aa5a475c65ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d6484f1ebd0f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMulti30k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBucketIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Field' from 'torchtext.data' (/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0 --quiet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import random\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from pprint import pprint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nENM1aZFVem7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c1a446d-7eba-4bb3-f79f-68745af32b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/gdrive') # Only needed if your data is on google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read JSON data from file\n",
        "with open('/gdrive/MyDrive/test_data1_final.json', 'r') as file:\n",
        "    test_data = json.load(file)"
      ],
      "metadata": {
        "id": "2YRYpdQ-cTFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWatomKYc1f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4edbd48-b3c2-4aef-d124-7adc07f25ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language Pair: English-Bengali\n",
            "  Data Type: Test\n",
            "Language Pair: English-Gujarati\n",
            "  Data Type: Test\n",
            "Language Pair: English-Hindi\n",
            "  Data Type: Test\n",
            "Language Pair: English-Kannada\n",
            "  Data Type: Test\n",
            "Language Pair: English-Malayalam\n",
            "  Data Type: Test\n",
            "Language Pair: English-Tamil\n",
            "  Data Type: Test\n",
            "Language Pair: English-Telgu\n",
            "  Data Type: Test\n"
          ]
        }
      ],
      "source": [
        "test_source = []\n",
        "valid_id = []\n",
        "len_val=[]\n",
        "\n",
        "\n",
        "for language_pair, language_data in test_data.items():\n",
        "      print(f\"Language Pair: {language_pair}\")\n",
        "      for data_type, data_entries in language_data.items():\n",
        "          print(f\"  Data Type: {data_type}\")\n",
        "          for entry_id, entry_data in data_entries.items():\n",
        "              source = entry_data[\"source\"]\n",
        "              test_source.append(source)\n",
        "              valid_id.append(entry_id)\n",
        "              len_val.append(len(source.split(' ')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_source)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMaZS3YeObUV",
        "outputId": "074e2d2c-398e-4eda-90ab-678a57d4c08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114647"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(len_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR3JdzR-DgTx",
        "outputId": "8d806933-fadb-4f86-ae83-994f96094cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file paths\n",
        "hindi = '/gdrive/MyDrive/hindi3.csv'\n",
        "tamil = '/gdrive/MyDrive/tamil3.csv'\n",
        "telugu = '/gdrive/MyDrive/telugu3.csv'\n",
        "malyalam = '/gdrive/MyDrive/malyalam3.csv'\n",
        "kannada = '/gdrive/MyDrive/kannada3.csv'\n",
        "gujarati = '/gdrive/MyDrive/gujrati3.csv'\n",
        "bengali = '/gdrive/MyDrive/bengali3.csv'\n",
        "\n",
        "# Read the CSV files into DataFrames\n",
        "df_hindi = pd.read_csv(hindi)\n",
        "df_tamil = pd.read_csv(tamil)\n",
        "df_telugu = pd.read_csv(telugu)\n",
        "df_malayalam = pd.read_csv(malyalam)\n",
        "df_kannada = pd.read_csv(kannada)\n",
        "df_gujarati = pd.read_csv(gujarati)\n",
        "df_bengali = pd.read_csv(bengali)\n",
        "\n",
        "ID = []\n",
        "Translation=[]\n",
        "\n",
        "for ids in df_bengali[\"valid_id\"]:\n",
        "  ID.append(ids)\n",
        "for p in df_bengali[\"bengali_pred\"]:\n",
        "  Translation.append(p)\n",
        "\n",
        "for ids in df_gujarati[\"valid_id\"]:\n",
        "  ID.append(ids)\n",
        "for p in df_gujarati[\"gujrati_pred\"]:\n",
        "  Translation.append(p)\n",
        "\n",
        "for ids in df_hindi[\"valid_id\"]:\n",
        "  ID.append(ids)\n",
        "for p in df_hindi[\"hindi_pred\"]:\n",
        "  Translation.append(p)\n",
        "\n",
        "for ids in df_kannada[\"valid_id\"]:\n",
        "  ID.append(ids)\n",
        "for p in df_kannada[\"kannada_pred\"]:\n",
        "  Translation.append(p)\n",
        "\n",
        "for ids in df_malayalam[\"valid_id\"]:\n",
        "  ID.append(ids)\n",
        "for p in df_malayalam[\"malyalam_pred\"]:\n",
        "  Translation.append(p)\n",
        "\n",
        "for ids in df_tamil[\"valid_id\"]:\n",
        "  ID.append(ids)\n",
        "for p in df_tamil[\"tamil_pred\"]:\n",
        "  Translation.append(p)\n",
        "\n",
        "for ids in df_telugu[\"valid_id\"]:\n",
        "  ID.append(ids)\n",
        "for p in df_telugu[\"telugu_pred\"]:\n",
        "  Translation.append(p)\n"
      ],
      "metadata": {
        "id": "TkHAyVIUrd8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ID = [str(element) for element in ID]"
      ],
      "metadata": {
        "id": "PP8a9mG31joT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(ID)):\n",
        "  if (ID[i]!=valid_id[i]):\n",
        "     print(\"ww\")\n",
        "     break"
      ],
      "metadata": {
        "id": "Vd7afL040FzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Create a list of dictionaries where each dictionary represents a row\n",
        "data = [{'ID': ID[i], 'Translation': Translation[i]} for i in range(len(ID))]\n",
        "\n",
        "# Specify the CSV file path\n",
        "csv_file_path = '/gdrive/MyDrive/answer_final.csv'\n",
        "\n",
        "# Define the column names\n",
        "fields = ['ID', 'Translation']\n",
        "\n",
        "# Write the data to the CSV file\n",
        "with open(csv_file_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fields, delimiter='\\t',quoting=csv.QUOTE_ALL)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(data)\n",
        "\n",
        "print(f'Saved predictions to {csv_file_path}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWPgDlRQyEoh",
        "outputId": "c3c497b5-8665-460c-b4eb-5db6753c0e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved predictions to /gdrive/MyDrive/answer_final.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}